---
title: "Clustering Traffic Accidents Using K-Means Clustering - Summer 2025"
subtitle: "This is a Report Template Quarto"
author: "Naveen Katepalli, Mrinal Mandapaka, Adiba Khan "
date: '`r Sys.Date()`'
format:
  html:
    code-fold: true
course: Capstone Projects in Data Science
bibliography: references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---

Slides: [slides.html](slides.html){target="_blank"} ( Go to `slides.qmd`
to edit)

::: callout-important
**Remember:** Your goal is to make your audience understand and care
about your findings. By crafting a compelling story, you can effectively
communicate the value of your data science project.

Carefully read this template since it has instructions and tips to
writing!
:::

## Introduction
## Project Overview

This capstone project applies **K-Means Clustering** to analyze traffic accident data, aiming to identify high-risk areas (“hotspots”) and uncover contributing factors such as location, time, weather, or road conditions. By grouping similar accidents into clusters, the project provides actionable insights for transportation authorities to implement targeted safety measures, reducing accident frequency and severity  
*(Road accident prediction and model interpretation using a hybrid K-means and random forest algorithm approach, Discover Applied Sciences, 2020).*

## K-Means Clustering for Traffic Accident Analysis

K-Means Clustering, an unsupervised learning algorithm, segments traffic accident data into K clusters, ensuring incidents within a cluster share similar characteristics while differing from other clusters  
*(Sinaga & Yang, IEEE Access, 2020; Bao Chong, Francis Academic Press, 2021).*

The process involves:

- **Centroid Initialization**: Select K initial centroids, ideally using PCA to enhance convergence *(Zubair et al., ICECTE, 2022)*.
- **Data Assignment**: Assign each accident record to the nearest centroid using features like geographic coordinates, time, or weather *(Fahlevi et al., 2020)*.
- **Centroid Update**: Recalculate centroids as the mean of assigned points *(Dubey et al., 2013)*.
- **Iteration**: Repeat until clusters stabilize *(Javadi et al., 2017)*.

This project uses datasets like NYC construction-related accidents or Indian traffic data to cluster incidents by spatial, temporal, or environmental factors  
*(Journal of Big Data, 2015; GitHub workzone-collision-analysis, 2020).*

## Determining the Optimal Number of Clusters

To ensure meaningful clusters, the following methods were used:

- **Elbow Method**: Plots SSE against K to find the “elbow” point  
*(Syakur et al., 2018)*.
- **Silhouette Method**: Uses silhouette coefficients (-1 to 1) to evaluate cluster quality  
*(Rousseeuw, 1987; Shi et al., 2021)*.
- **Gap Statistic**: Compares within-cluster dispersion to a reference distribution  
*(Tibshirani et al., 2001)*.

Weighted variants like **Silhouette-Coefficient Based Weighting K-Means** and **K-Sil** were explored to improve clustering accuracy *(Lai et al., 2024; Semoglou et al., arXiv, 2025).*

## Optimization and Preprocessing

The **Canopy algorithm** was used to partition large datasets before clustering  
*(Yuan & Yang, 2019; IEEE, 2020)*.  
**PCA** was applied to reduce dimensionality and focus on key features like location or road conditions *(Zubair et al., 2022)*.

## Cluster Quality Evaluation

Cluster validity was evaluated using the **Calinski-Harabasz index**, where higher values indicate better-defined clusters  
*(Qabbaah et al., 2019).*

# Methods

The project applies K-Means clustering on traffic accident datasets to identify geographic and temporal hotspots. Several real-world applications guided our methodology:

- **London**: K-Means + KDE to group accidents into 15 environmental clusters  
*(ScienceDirect, 2007)*
- **India**: K-Modes + Association Rule Mining on 11,574 accidents  
*(Journal of Big Data, 2015)*
- **Colombia**: Clustered zones using venue composition in Medellín  
*(ScienceDirect, 2020)*

This project analyzed over 20,000 NYC construction-related incidents to uncover high-risk road segments due to factors like lighting or geometry  
*(Scientific Reports, 2024).*

## Variations of K-Means

Enhanced techniques explored:

- **Constrained K-Means** for consistent cluster sizes *(Usami, 2014)*
- **Improved K-Means** for large datasets *(Na et al., 2010)*
- **Filtering Algorithms** using kd-trees *(Kanungo et al., 2002)*
- **GBKM** with genetic algorithms *(Chougule et al., 2015)*
- **MapReduce K-Means** for big data *(Anchalia et al., 2013)*
- **Silhouette-Weighted K-Means** for improved separation *(Semoglou et al., 2025)*

## Limitations

K-Means can suffer from:

- Random centroid initialization
- Sensitivity to the pre-set number of clusters
- Difficulty with heterogeneous data

To address this, preprocessing included feature scaling, handling missing values, and testing different initialization strategies  
*(Ahmed et al., 2020; Wikipedia, 2025).*

## Project Impact

By identifying hotspots and accident patterns, this project supports targeted infrastructure improvements like better lighting or signage. The findings align with other major studies in London and Medellín, offering scalable, data-driven safety interventions  
*(Discover Applied Sciences, 2020; ScienceDirect, 2007 & 2020).*


## Methods

-   Detail the models or algorithms used.

-   Justify your choices based on the problem and data.

*The common non-parametric regression model is*
$Y_i = m(X_i) + \varepsilon_i$*, where* $Y_i$ *can be defined as the sum
of the regression function value* $m(x)$ *for* $X_i$*. Here* $m(x)$ *is
unknown and* $\varepsilon_i$ *some errors. With the help of this
definition, we can create the estimation for local averaging i.e.*
$m(x)$ *can be estimated with the product of* $Y_i$ *average and* $X_i$
*is near to* $x$*. In other words, this means that we are discovering
the line through the data points with the help of surrounding data
points. The estimation formula is printed below [@R-base]:*

$$
M_n(x) = \sum_{i=1}^{n} W_n (X_i) Y_i  \tag{1}
$$$W_n(x)$ *is the sum of weights that belongs to all real numbers.
Weights are positive numbers and small if* $X_i$ *is far from* $x$*.*


*Another equation:*

$$
y_i = \beta_0 + \beta_1 X_1 +\varepsilon_i
$$

## Analysis and Results

### Data Exploration and Visualization

-   Describe your data sources and collection process.

-   Present initial findings and insights through visualizations.

-   Highlight unexpected patterns or anomalies.

A study was conducted to determine how...

```{r, warning=FALSE, echo=T, message=FALSE}
# loading packages 
library(tidyverse)
library(knitr)
library(ggthemes)
library(ggrepel)
library(dslabs)
```

```{r, warning=FALSE, echo=TRUE}
# Load Data
kable(head(murders))

ggplot1 = murders %>% ggplot(mapping = aes(x=population/10^6, y=total)) 

  ggplot1 + geom_point(aes(col=region), size = 4) +
  geom_text_repel(aes(label=abb)) +
  scale_x_log10() +
  scale_y_log10() +
  geom_smooth(formula = "y~x", method=lm,se = F)+
  xlab("Populations in millions (log10 scale)") + 
  ylab("Total number of murders (log10 scale)") +
  ggtitle("US Gun Murders in 2010") +
  scale_color_discrete(name = "Region")+
      theme_bw()
  

```

### Modeling and Results

-   Explain your data preprocessing and cleaning steps.

-   Present your key findings in a clear and concise manner.

-   Use visuals to support your claims.

-   **Tell a story about what the data reveals.**

```{r}

```

### Conclusion

-   Summarize your key findings.

-   Discuss the implications of your results.

## References
